{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasa_nlu.model import Interpreter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_config' (str) to file 'nlu_config.yml'.\n"
     ]
    }
   ],
   "source": [
    "# nlu_config = \"\"\"\n",
    "# language: fr\n",
    "# pipeline: tensorflow_embedding\n",
    "# \"\"\"\n",
    "\n",
    "nlu_config = \"\"\"\n",
    "language: fr\n",
    "pipeline:\n",
    "- name: \"nlp_spacy\"\n",
    "- name: \"tokenizer_spacy\"\n",
    "- name: \"intent_featurizer_spacy\"\n",
    "- name: \"intent_entity_featurizer_regex\"\n",
    "- name: \"ner_crf\"\n",
    "- name: \"ner_synonyms\"\n",
    "- name: \"intent_classifier_sklearn\"\n",
    "\"\"\"\n",
    "\n",
    "# nlu_config = \"\"\"\n",
    "# language: fr\n",
    "# pipeline: \"spacy_sklearn\"\n",
    "# \"\"\"\n",
    "\n",
    "%store nlu_config > nlu_config.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'nlu_md' (str) to file 'nlu.md'.\n"
     ]
    }
   ],
   "source": [
    "nlu_md = \"\"\"\n",
    "## intent:hello\n",
    "- salut\n",
    "- bonjour\n",
    "- hey\n",
    "- hello\n",
    "- coucou\n",
    "- yo\n",
    "\n",
    "## intent:search_dataset\n",
    "- statistiques de [la ville de paris](organization)\n",
    "- je cherche [les données](object) du [ministère de l'intérieur](organization)\n",
    "- j'aimerai connaitre la [qualité de l'air](topic) à Paris\n",
    "- Je voudrai avoir [les chiffres](object) de la [population française](topic)\n",
    "- quel est [mon numéro](object) [RNA](topic) ?\n",
    "- poule 2010\n",
    "- je veux des données\n",
    "- [vigicrue](topic) 2018\n",
    "- base [SIRENE](topic)\n",
    "\n",
    "## intent:confirm\n",
    "- oui\n",
    "- ouais\n",
    "- ouaip\n",
    "- ui\n",
    "- hum oui\n",
    "- hmm ui\n",
    "- ok\n",
    "- c'est ça\n",
    "- yes\n",
    "\n",
    "## intent:deny\n",
    "- non\n",
    "- pas du tout\n",
    "- nope\n",
    "- oui mais non\n",
    "- hm non\n",
    "- hum non\n",
    "- no\n",
    "\n",
    "## intent:thankyou\n",
    "- merci\n",
    "- c'est chouette\n",
    "- cool !\n",
    "- super !\n",
    "\n",
    "## intent:bye\n",
    "- au revoir\n",
    "- à plus\n",
    "- bye\n",
    "- ciao\n",
    "- bonne nuit\n",
    "\n",
    "## lookup:organization\n",
    "organisations.txt\n",
    "\n",
    "## lookup:topic\n",
    "datasets.txt\n",
    "\n",
    "## regex:year\n",
    "- [0-9]{4}\n",
    "\"\"\"\n",
    "%store nlu_md > nlu.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## importation des noms d'organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../pilotage/data/organizations.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'txt' (str) to file 'organisations.txt'.\n"
     ]
    }
   ],
   "source": [
    "names = [ x for x in list(df1['name'].astype(str).values) if x != 'nan' ]\n",
    "accronyms = [ x for x in list(df1['acronym'].astype(str).values) if x != 'nan' ]\n",
    "\n",
    "txt = \"\\n\".join(names + accronyms)\n",
    "%store txt > organisations.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tk/.virtualenvs/notebooks/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv('../pilotage/data/datasets.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing 'txt' (str) to file 'datasets.txt'.\n"
     ]
    }
   ],
   "source": [
    "df2.head()\n",
    "\n",
    "names = [ x for x in list(df2['title'].astype(str).values) if x != 'nan' ]\n",
    "accronyms = [ x for x in list(df2['acronym'].astype(str).values) if x != 'nan' ]\n",
    "\n",
    "txt = \"\\n\".join(names + accronyms)\n",
    "%store txt > datasets.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-31 12:13:51 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.utils.spacy_utils\u001b[0m  - Trying to load spacy model with name 'fr'\n",
      "2019-01-31 12:13:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.components\u001b[0m  - Added 'nlp_spacy' to component cache. Key 'nlp_spacy-fr'.\n",
      "2019-01-31 12:13:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.loading\u001b[0m  - Training data format of nlu.md is md\n",
      "2019-01-31 12:13:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.training_data.training_data\u001b[0m  - Training data stats: \n",
      "\t- intent examples: 40 (6 distinct intents)\n",
      "\t- Found intents: 'confirm', 'thankyou', 'hello', 'deny', 'bye', 'search_dataset'\n",
      "\t- entity examples: 7 (3 distinct entities)\n",
      "\t- found entities: 'topic', 'organization', 'object'\n",
      "\n",
      "2019-01-31 12:13:58 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component nlp_spacy\n",
      "2019-01-31 12:13:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-01-31 12:13:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component tokenizer_spacy\n",
      "2019-01-31 12:13:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-01-31 12:13:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component intent_featurizer_spacy\n",
      "2019-01-31 12:13:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-01-31 12:13:59 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component intent_entity_featurizer_regex\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component ner_crf\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component ner_synonyms\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Starting to train component intent_classifier_sklearn\n",
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "/home/tk/.virtualenvs/notebooks/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/tk/.virtualenvs/notebooks/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/tk/.virtualenvs/notebooks/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/tk/.virtualenvs/notebooks/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/tk/.virtualenvs/notebooks/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/tk/.virtualenvs/notebooks/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Finished training component.\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34mrasa_nlu.model\u001b[0m  - Successfully saved model into '/home/tk/notebooks/data.gouv.fr/searchbot/models/current/nlu'\n",
      "2019-01-31 12:14:05 \u001b[1;30mINFO    \u001b[0m \u001b[34m__main__\u001b[0m  - Finished training\n"
     ]
    }
   ],
   "source": [
    "!python -m rasa_nlu.train -c nlu_config.yml --data nlu.md -o models --fixed_model_name nlu --project current --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = Interpreter.load(\"./models/current/nlu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"search_dataset\",\n",
      "    \"confidence\": 0.37504581892005423\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"search_dataset\",\n",
      "      \"confidence\": 0.37504581892005423\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.16469573942343668\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"confirm\",\n",
      "      \"confidence\": 0.1479097845543902\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"hello\",\n",
      "      \"confidence\": 0.1188168084682127\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thankyou\",\n",
      "      \"confidence\": 0.1121113661456479\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"bye\",\n",
      "      \"confidence\": 0.0814204824882585\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"Pays de Morlaix 2017\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = \"Pays de Morlaix 2017\"\n",
    "result = interpreter.parse(message)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"confirm\",\n",
      "    \"confidence\": 0.28726857647984166\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"confirm\",\n",
      "      \"confidence\": 0.28726857647984166\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.22217696580285237\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"hello\",\n",
      "      \"confidence\": 0.20043180588287685\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"bye\",\n",
      "      \"confidence\": 0.1288506139988975\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thankyou\",\n",
      "      \"confidence\": 0.10419230006202315\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"search_dataset\",\n",
      "      \"confidence\": 0.05707973777350827\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"oui\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = \"oui\"\n",
    "result = interpreter.parse(message)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"intent\": {\n",
      "    \"name\": \"deny\",\n",
      "    \"confidence\": 0.2639537437459718\n",
      "  },\n",
      "  \"entities\": [],\n",
      "  \"intent_ranking\": [\n",
      "    {\n",
      "      \"name\": \"deny\",\n",
      "      \"confidence\": 0.2639537437459718\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"confirm\",\n",
      "      \"confidence\": 0.23351412650327888\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"hello\",\n",
      "      \"confidence\": 0.14857869023961762\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"bye\",\n",
      "      \"confidence\": 0.13550775547498314\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"thankyou\",\n",
      "      \"confidence\": 0.11207979421263056\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"search_dataset\",\n",
      "      \"confidence\": 0.10636588982351801\n",
      "    }\n",
      "  ],\n",
      "  \"text\": \"non\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = \"non\"\n",
    "result = interpreter.parse(message)\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
